{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an enterprise setting, a data warehouse serves as a data repository. It can store not only relational data, but also semi-structured and unstructured data. It is a system for reporting and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Star Schema is a combination of facts and dimensions for storing data. It consists of one or more fact tables referencing any number of dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For example, one database of sales can be keeping the main data about each sales, and then, it can be referencing to store, product and date databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the database world, 3NF (Third Normal Form) is a normal form used in normalizing a database design to reduce the duplication of data and ensure referential integrity by ensuring that the entity is in second normal form and that all the attributes in a table are determined only by the candidate keys of that table and not by any non-prime attributes. It was designed to improve database processing while minimizing storage costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning also consumes data with joining. One would use denormalized log files to extract features or variables from these logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MRJob, implement a hashside join (memory-backed map-side) for left, \n",
    "right and inner joins. Run your code on the  data used in HW 4.4: (Recall HW 4.4: Find the most frequent visitor of each page using mrjob and the output of 4.2  (i.e., transfromed log file). In this output please include the webpage URL, webpageID and Visitor ID.)\n",
    ":\n",
    "\n",
    "Justify which table you chose as the Left table in this hashside join.\n",
    "\n",
    "Please report the number of rows resulting from:\n",
    "\n",
    "(1) Left joining Table Left with Table Right\n",
    "\n",
    "(2) Right joining Table Left with Table Right\n",
    "\n",
    "(3) Inner joining Table Left with Table Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## first, we get the data from our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-07-16 13:45:24--  https://www.dropbox.com/sh/m0nxsf4vs5cyrp2/AADCHtrJ4CBCDO1po_OAWg0ia/anonymous-msweb.data?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://dl.dropboxusercontent.com/content_link/4fs1tHJE0tBZeTztiQLvEGJZkUlrXMn647C6Fm0pwKyleryHrXxVRpJ3IUXZuuHM/file [following]\n",
      "--2016-07-16 13:45:25--  https://dl.dropboxusercontent.com/content_link/4fs1tHJE0tBZeTztiQLvEGJZkUlrXMn647C6Fm0pwKyleryHrXxVRpJ3IUXZuuHM/file\n",
      "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 108.160.173.165\n",
      "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|108.160.173.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1423098 (1.4M) [text/plain]\n",
      "Saving to: ‘anonymous-msweb.data?dl=0.1’\n",
      "\n",
      "100%[======================================>] 1,423,098   3.22MB/s   in 0.4s   \n",
      "\n",
      "2016-07-16 13:45:27 (3.22 MB/s) - ‘anonymous-msweb.data?dl=0.1’ saved [1423098/1423098]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/sh/m0nxsf4vs5cyrp2/AADCHtrJ4CBCDO1po_OAWg0ia/anonymous-msweb.data?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv anonymous-msweb.data?dl=0 anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,4,\"www.microsoft.com\",\"created by getlog.pl\"\r\n",
      "T,1,\"VRoot\",0,0,\"VRoot\"\r\n",
      "N,0,\"0\"\r\n",
      "N,1,\"1\"\r\n",
      "T,2,\"Hide1\",0,0,\"Hide\"\r\n",
      "N,0,\"0\"\r\n",
      "N,1,\"1\"\r\n",
      "A,1287,1,\"International AutoRoute\",\"/autoroute\"\r\n",
      "A,1288,1,\"library\",\"/library\"\r\n",
      "A,1289,1,\"Master Chef Product Information\",\"/masterchef\"\r\n",
      "A,1297,1,\"Central America\",\"/centroam\"\r\n",
      "A,1215,1,\"For Developers Only Info\",\"/developer\"\r\n",
      "A,1279,1,\"Multimedia Golf\",\"/msgolf\"\r\n",
      "A,1239,1,\"Microsoft Consulting\",\"/msconsult\"\r\n",
      "A,1282,1,\"home\",\"/home\"\r\n",
      "A,1251,1,\"Reference Support\",\"/referencesupport\"\r\n",
      "A,1121,1,\"Microsoft Magazine\",\"/magazine\"\r\n",
      "A,1083,1,\"MS Access Support\",\"/msaccesssupport\"\r\n",
      "A,1145,1,\"Visual Fox Pro Support\",\"/vfoxprosupport\"\r\n",
      "A,1276,1,\"Visual Test Support\",\"/vtestsupport\"\r\n",
      "A,1200,1,\"Benelux Region\",\"/benelux\"\r\n",
      "A,1259,1,\"controls\",\"/controls\"\r\n",
      "A,1155,1,\"Sidewalk\",\"/sidewalk\"\r\n",
      "A,1092,1,\"Visual FoxPro\",\"/vfoxpro\"\r\n",
      "A,1004,1,\"Microsoft.com Search\",\"/search\"\r\n",
      "A,1057,1,\"MS PowerPoint News\",\"/powerpoint\"\r\n",
      "A,1140,1,\"Netherlands (Holland)\",\"/netherlands\"\r\n",
      "A,1198,1,\"Picture It\",\"/pictureit\"\r\n",
      "A,1147,1,\"Microsoft Financial Forum\",\"/msft\"\r\n",
      "A,1005,1,\"Norway\",\"/norge\"\r\n",
      "A,1026,1,\"Internet Site Construction for Developers\",\"/sitebuilder\"\r\n",
      "A,1119,1,\"Corporation Information\",\"/corpinfo\"\r\n",
      "A,1216,1,\"Virtual Reality Markup Language\",\"/vrml\"\r\n",
      "A,1218,1,\"MS Publisher Support\",\"/publishersupport\"\r\n",
      "A,1205,1,\"Hardware Supprt\",\"/hardwaresupport\"\r\n",
      "A,1269,1,\"Customer Guides\",\"/business\"\r\n",
      "A,1031,1,\"MS Office\",\"/msoffice\"\r\n",
      "A,1003,1,\"Knowledge Base\",\"/kb\"\r\n",
      "A,1238,1,\"Excel Development\",\"/exceldev\"\r\n",
      "A,1118,1,\"SQL Server\",\"/sql\"\r\n",
      "A,1242,1,\"MS Garden\",\"/msgarden\"\r\n",
      "A,1171,1,\"MS Merchant\",\"/merchant\"\r\n",
      "A,1175,1,\"MS Project Support\",\"/msprojectsupport\"\r\n",
      "A,1021,1,\"Visual C\",\"/visualc\"\r\n",
      "A,1222,1,\"MS Office News\",\"/msofc\"\r\n",
      "A,1284,1,\"partner\",\"/partner\"\r\n",
      "A,1294,1,\"Bookshelf\",\"/bookshelf\"\r\n",
      "A,1053,1,\"Jakarta\",\"/visualj\"\r\n",
      "A,1293,1,\"Encarta\",\"/encarta\"\r\n",
      "A,1167,1,\"Windows Hardware Testing\",\"/hwtest\"\r\n",
      "A,1202,1,\"Advanced Technology\",\"/advtech\"\r\n",
      "A,1234,1,\"Office Free Stuff News\",\"/off97cat\"\r\n",
      "A,1054,1,\"Exchange\",\"/exchange\"\r\n",
      "A,1262,1,\"Chile\",\"/chile\"\r\n",
      "A,1074,1,\"Windows NT Workstation\",\"/ntworkstation\"\r\n"
     ]
    }
   ],
   "source": [
    "#first check how does the file look like\n",
    "! head -55 anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "open(\"anonymous-msweb-preprocessed.data\", \"w\").close\n",
    "custID = \"NA\"\n",
    "with open(\"anonymous-msweb.data\", \"r\") as IF:\n",
    "    for line in IF:\n",
    "        line = line.strip()\n",
    "        data = re.split(\",\",line)\n",
    "        if data[0] == \"C\":\n",
    "            custID = data[1]\n",
    "            custID = re.sub(\"\\\"\",\"\",custID)\n",
    "        if data[0] == \"V\" and not custID == \"NA\":\n",
    "            with open(\"anonymous-msweb-preprocessed.data\", \"a\") as OF:\n",
    "                OF.writelines(line+\",\"+\"C\"+\",\"+custID+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,1000,1,C,10001\r\n",
      "V,1001,1,C,10001\r\n",
      "V,1002,1,C,10001\r\n",
      "V,1001,1,C,10002\r\n",
      "V,1003,1,C,10002\r\n",
      "V,1001,1,C,10003\r\n",
      "V,1003,1,C,10003\r\n",
      "V,1004,1,C,10003\r\n",
      "V,1005,1,C,10004\r\n",
      "V,1006,1,C,10005\r\n"
     ]
    }
   ],
   "source": [
    "! head anonymous-msweb-preprocessed.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with this data in the same way as in the class example. The difference is that we are dealing with a dataset of visitors and visits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Left join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to print out what visitor visited what page. This is the same as our class example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducersideleftjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersideleftjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.compat import jobconf_from_env\n",
    "import re\n",
    " \n",
    "class leftjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        x = line.split(\",\")\n",
    "        if len(x) == 5:\n",
    "            ## if we're dealing with the page visiting history:\n",
    "            if x[0]==\"V\":\n",
    "                yield x[0], (\"lefttable\", x[1], x[2], x[3], x[4])\n",
    "            ## if we're dealing with the page info:\n",
    "            if x[0] == \"A\":\n",
    "                yield x[0], (\"righttable\", x[1], x[2], x[3], x[4])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        pagename = list()\n",
    "        pagevisits = list()\n",
    "        for val in values:\n",
    "            if val[0]== u'lefttable':\n",
    "                pagevisits.append(val)\n",
    "            else:\n",
    "                pagename.append(val)\n",
    "        # this is what makes the result of the query different\n",
    "        # based on the table on which we are joining:\n",
    "        for c in pagename:\n",
    "            if len(pagevisits)==0:\n",
    "                yield None, [key] + c[1:] + [None] \n",
    "            for o in pagevisits:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    leftjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'A', u'1000', u'1', u'\"regwiz\"', u'\"/regwiz\"', None]\n",
      "[u'A', u'1001', u'1', u'\"Support Desktop\"', u'\"/support\"', None]\n",
      "[u'A', u'1002', u'1', u'\"End User Produced View\"', u'\"/athome\"', None]\n",
      "[u'A', u'1003', u'1', u'\"Knowledge Base\"', u'\"/kb\"', None]\n",
      "[u'A', u'1004', u'1', u'\"Microsoft.com Search\"', u'\"/search\"', None]\n",
      "[u'A', u'1005', u'1', u'\"Norway\"', u'\"/norge\"', None]\n",
      "[u'A', u'1006', u'1', u'\"misc\"', u'\"/misc\"', None]\n",
      "[u'A', u'1007', u'1', u'\"International IE content\"', u'\"/ie_intl\"', None]\n",
      "[u'A', u'1008', u'1', u'\"Free Downloads\"', u'\"/msdownload\"', None]\n",
      "[u'A', u'1009', u'1', u'\"Windows Family of OSs\"', u'\"/windows\"', None]\n",
      "[u'A', u'1010', u'1', u'\"Visual Basic\"', u'\"/vbasic\"', None]\n",
      "[u'A', u'1011', u'1', u'\"MS Office Development\"', u'\"/officedev\"', None]\n",
      "[u'A', u'1012', u'1', u'\"Outlook Development\"', u'\"/outlookdev\"', None]\n",
      "[u'A', u'1013', u'1', u'\"Visual Basic Support\"', u'\"/vbasicsupport\"', None]\n",
      "[u'A', u'1014', u'1', u'\"Office Free Stuff\"', u'\"/officefreestuff\"', None]\n",
      "[u'A', u'1015', u'1', u'\"Excel\"', u'\"/msexcel\"', None]\n",
      "[u'A', u'1016', u'1', u'\"MS Excel\"', u'\"/excel\"', None]\n",
      "[u'A', u'1017', u'1', u'\"Products \"', u'\"/products\"', None]\n",
      "[u'A', u'1018', u'1', u'\"isapi\"', u'\"/isapi\"', None]\n",
      "[u'A', u'1019', u'1', u'\"MS PowerPoint\"', u'\"/mspowerpoint\"', None]\n",
      "[u'A', u'1020', u'1', u'\"Developer Network\"', u'\"/msdn\"', None]\n",
      "[u'A', u'1021', u'1', u'\"Visual C\"', u'\"/visualc\"', None]\n",
      "[u'A', u'1022', u'1', u'\"Typography Site\"', u'\"/truetype\"', None]\n",
      "[u'A', u'1023', u'1', u'\"Spain\"', u'\"/spain\"', None]\n",
      "[u'A', u'1024', u'1', u'\"Internet Information Server\"', u'\"/iis\"', None]\n",
      "[u'A', u'1025', u'1', u'\"Web Site Builder\\'s Gallery\"', u'\"/gallery\"', None]\n",
      "[u'A', u'1026', u'1', u'\"Internet Site Construction for Developers\"', u'\"/sitebuilder\"', None]\n",
      "[u'A', u'1027', u'1', u'\"Internet Development\"', u'\"/intdev\"', None]\n",
      "[u'A', u'1028', u'1', u'\"OLE Development\"', u'\"/oledev\"', None]\n",
      "[u'A', u'1029', u'1', u'\"Clip Gallery Live\"', u'\"/clipgallerylive\"', None]\n",
      "[u'A', u'1030', u'1', u'\"Windows NT Server\"', u'\"/ntserver\"', None]\n",
      "[u'A', u'1031', u'1', u'\"MS Office\"', u'\"/msoffice\"', None]\n",
      "[u'A', u'1032', u'1', u'\"Games\"', u'\"/games\"', None]\n",
      "[u'A', u'1033', u'1', u'\"MS Store Logo Merchandise\"', u'\"/logostore\"', None]\n",
      "[u'A', u'1034', u'1', u'\"Internet Explorer\"', u'\"/ie\"', None]\n",
      "[u'A', u'1035', u'1', u'\"Windows95 Support\"', u'\"/windowssupport\"', None]\n",
      "[u'A', u'1036', u'1', u'\"Corporate Desktop Evaluation\"', u'\"/organizations\"', None]\n",
      "[u'A', u'1037', u'1', u'\"Windows 95\"', u'\"/windows95\"', None]\n",
      "[u'A', u'1038', u'1', u'\"SiteBuilder Network Membership\"', u'\"/sbnmember\"', None]\n",
      "[u'A', u'1039', u'1', u'\"Internet Service Providers\"', u'\"/isp\"', None]\n",
      "[u'A', u'1040', u'1', u'\"MS Office Info\"', u'\"/office\"', None]\n",
      "[u'A', u'1041', u'1', u'\"Developer Workshop\"', u'\"/workshop\"', None]\n",
      "[u'A', u'1042', u'1', u'\"Visual Studio\"', u'\"/vstudio\"', None]\n",
      "[u'A', u'1043', u'1', u'\"Connecting Small Business\"', u'\"/smallbiz\"', None]\n",
      "[u'A', u'1044', u'1', u'\"Developer Media Development\"', u'\"/mediadev\"', None]\n",
      "[u'A', u'1045', u'1', u'\"NetMeeting\"', u'\"/netmeeting\"', None]\n",
      "[u'A', u'1046', u'1', u'\"IE Support\"', u'\"/iesupport\"', None]\n",
      "[u'A', u'1048', u'1', u'\"MS Publisher\"', u'\"/publisher\"', None]\n",
      "[u'A', u'1049', u'1', u'\"Support Network Program Information\"', u'\"/supportnet\"', None]\n",
      "[u'A', u'1050', u'1', u'\"Macintosh Office\"', u'\"/macoffice\"', None]\n",
      "[u'A', u'1051', u'1', u'\"MS Schedule+ News\"', u'\"/scheduleplus\"', None]\n",
      "[u'A', u'1052', u'1', u'\"MS Word News\"', u'\"/word\"', None]\n",
      "[u'A', u'1053', u'1', u'\"Jakarta\"', u'\"/visualj\"', None]\n",
      "[u'A', u'1054', u'1', u'\"Exchange\"', u'\"/exchange\"', None]\n",
      "[u'A', u'1055', u'1', u'\"MSHome Kids Stuff\"', u'\"/kids\"', None]\n",
      "[u'A', u'1056', u'1', u'\"sports\"', u'\"/sports\"', None]\n",
      "[u'A', u'1057', u'1', u'\"MS PowerPoint News\"', u'\"/powerpoint\"', None]\n",
      "[u'A', u'1058', u'1', u'\"SP Referral (ART)\"', u'\"/referral\"', None]\n",
      "[u'A', u'1059', u'1', u'\"Sweden\"', u'\"/sverige\"', None]\n",
      "[u'A', u'1060', u'1', u'\"MS Word\"', u'\"/msword\"', None]\n",
      "[u'A', u'1061', u'1', u'\"promo\"', u'\"/promo\"', None]\n",
      "[u'A', u'1062', u'1', u'\"MS Access News\"', u'\"/msaccess\"', None]\n",
      "[u'A', u'1063', u'1', u'\"Intranet Strategy\"', u'\"/intranet\"', None]\n",
      "[u'A', u'1064', u'1', u'\"MS Site Builder Workshop\"', u'\"/activeplatform\"', None]\n",
      "[u'A', u'1065', u'1', u'\"Java Strategy and Info\"', u'\"/java\"', None]\n",
      "[u'A', u'1066', u'1', u'\"Music Producer\"', u'\"/musicproducer\"', None]\n",
      "[u'A', u'1067', u'1', u'\"FrontPage\"', u'\"/frontpage\"', None]\n",
      "[u'A', u'1068', u'1', u'\"VBScript Development\"', u'\"/vbscript\"', None]\n",
      "[u'A', u'1069', u'1', u'\"Windows CE\"', u'\"/windowsce\"', None]\n",
      "[u'A', u'1070', u'1', u'\"ActiveX Technology Development\"', u'\"/activex\"', None]\n",
      "[u'A', u'1071', u'1', u'\"N. American Automap\"', u'\"/automap\"', None]\n",
      "[u'A', u'1072', u'1', u'\"Visual InterDev\"', u'\"/vinterdev\"', None]\n",
      "[u'A', u'1073', u'1', u'\"Taiwan\"', u'\"/taiwan\"', None]\n",
      "[u'A', u'1074', u'1', u'\"Windows NT Workstation\"', u'\"/ntworkstation\"', None]\n",
      "[u'A', u'1075', u'1', u'\"Job Openings\"', u'\"/jobs\"', None]\n",
      "[u'A', u'1076', u'1', u'\"NT Workstation Support\"', u'\"/ntwkssupport\"', None]\n",
      "[u'A', u'1077', u'1', u'\"MS Office Support\"', u'\"/msofficesupport\"', None]\n",
      "[u'A', u'1078', u'1', u'\"NT Server Support\"', u'\"/ntserversupport\"', None]\n",
      "[u'A', u'1079', u'1', u'\"Australia\"', u'\"/australia\"', None]\n",
      "[u'A', u'1080', u'1', u'\"Brazil\"', u'\"/brasil\"', None]\n",
      "[u'A', u'1081', u'1', u'\"Access Development\"', u'\"/accessdev\"', None]\n",
      "[u'A', u'1082', u'1', u'\"MS Access\"', u'\"/access\"', None]\n",
      "[u'A', u'1083', u'1', u'\"MS Access Support\"', u'\"/msaccesssupport\"', None]\n",
      "[u'A', u'1084', u'1', u'\"UK\"', u'\"/uk\"', None]\n",
      "[u'A', u'1085', u'1', u'\"Exchange Support\"', u'\"/exchangesupport\"', None]\n",
      "[u'A', u'1086', u'1', u'\"OEM\"', u'\"/oem\"', None]\n",
      "[u'A', u'1087', u'1', u'\"MS Proxy Server\"', u'\"/proxy\"', None]\n",
      "[u'A', u'1088', u'1', u'\"OutLook\"', u'\"/outlook\"', None]\n",
      "[u'A', u'1089', u'1', u'\"Office Reference\"', u'\"/officereference\"', None]\n",
      "[u'A', u'1090', u'1', u'\"Games Support\"', u'\"/gamessupport\"', None]\n",
      "[u'A', u'1091', u'1', u'\"Windows Hardware Development\"', u'\"/hwdev\"', None]\n",
      "[u'A', u'1092', u'1', u'\"Visual FoxPro\"', u'\"/vfoxpro\"', None]\n",
      "[u'A', u'1093', u'1', u'\"VBA Development\"', u'\"/vba\"', None]\n",
      "[u'A', u'1094', u'1', u'\"Microsoft Home\"', u'\"/mshome\"', None]\n",
      "[u'A', u'1095', u'1', u'\"Product Catalog\"', u'\"/catalog\"', None]\n",
      "[u'A', u'1096', u'1', u'\"Microsoft Press\"', u'\"/mspress\"', None]\n",
      "[u'A', u'1097', u'1', u'\"Latin America Region\"', u'\"/latam\"', None]\n",
      "[u'A', u'1098', u'1', u'\"For Developers Only\"', u'\"/devonly\"', None]\n",
      "[u'A', u'1099', u'1', u'\"Executive Computing\"', u'\"/cio\"', None]\n",
      "[u'A', u'1100', u'1', u'\"MS in Education\"', u'\"/education\"', None]\n",
      "[u'A', u'1101', u'1', u'\"Microsoft OLE DB\"', u'\"/oledb\"', None]\n",
      "[u'A', u'1102', u'1', u'\"Microsoft Home Essentials\"', u'\"/homeessentials\"', None]\n",
      "[u'A', u'1103', u'1', u'\"MS Works\"', u'\"/works\"', None]\n",
      "[u'A', u'1104', u'1', u'\"Hong Kong\"', u'\"/hk\"', None]\n",
      "[u'A', u'1105', u'1', u'\"France\"', u'\"/france\"', None]\n",
      "[u'A', u'1106', u'1', u'\"Czech Republic\"', u'\"/cze\"', None]\n",
      "[u'A', u'1107', u'1', u'\"Slovakia\"', u'\"/slovakia\"', None]\n",
      "[u'A', u'1108', u'1', u'\"MS TeamManager\"', u'\"/teammanager\"', None]\n",
      "[u'A', u'1109', u'1', u'\"TechNet (World Wide Web Edition)\"', u'\"/technet\"', None]\n",
      "[u'A', u'1110', u'1', u'\"Mastering Series\"', u'\"/mastering\"', None]\n",
      "[u'A', u'1111', u'1', u'\"Visual Source Safe\"', u'\"/ssafe\"', None]\n",
      "[u'A', u'1112', u'1', u'\"Canada\"', u'\"/canada\"', None]\n",
      "[u'A', u'1113', u'1', u'\"Internet Security Framework\"', u'\"/security\"', None]\n",
      "[u'A', u'1114', u'1', u'\"Service Advantage\"', u'\"/servad\"', None]\n",
      "[u'A', u'1115', u'1', u'\"Hungary\"', u'\"/hun\"', None]\n",
      "[u'A', u'1116', u'1', u'\"Switzerland\"', u'\"/switzerland\"', None]\n",
      "[u'A', u'1117', u'1', u'\"Sidewinder\"', u'\"/sidewinder\"', None]\n",
      "[u'A', u'1118', u'1', u'\"SQL Server\"', u'\"/sql\"', None]\n",
      "[u'A', u'1119', u'1', u'\"Corporation Information\"', u'\"/corpinfo\"', None]\n",
      "[u'A', u'1120', u'1', u'\"Switching from Competitive Products\"', u'\"/switch\"', None]\n",
      "[u'A', u'1121', u'1', u'\"Microsoft Magazine\"', u'\"/magazine\"', None]\n",
      "[u'A', u'1122', u'1', u'\"Microsoft User Group Program\"', u'\"/mindshare\"', None]\n",
      "[u'A', u'1123', u'1', u'\"Germany\"', u'\"/germany\"', None]\n",
      "[u'A', u'1124', u'1', u'\"Industry Marketing Information (Vertical)\"', u'\"/industry\"', None]\n",
      "[u'A', u'1125', u'1', u'\"ImageComposer\"', u'\"/imagecomposer\"', None]\n",
      "[u'A', u'1126', u'1', u'\"Media Manager\"', u'\"/mediamanager\"', None]\n",
      "[u'A', u'1127', u'1', u'\"NetShow\"', u'\"/netshow\"', None]\n",
      "[u'A', u'1128', u'1', u'\"MS Solutions Framework\"', u'\"/msf\"', None]\n",
      "[u'A', u'1129', u'1', u'\"ActiveX Data Objects\"', u'\"/ado\"', None]\n",
      "[u'A', u'1130', u'1', u'\"IT Technical Information\"', u'\"/syspro\"', None]\n",
      "[u'A', u'1131', u'1', u'\"MS Money Information\"', u'\"/moneyzone\"', None]\n",
      "[u'A', u'1132', u'1', u'\"MS Money Support\"', u'\"/msmoneysupport\"', None]\n",
      "[u'A', u'1133', u'1', u'\"FrontPage Support\"', u'\"/frontpagesupport\"', None]\n",
      "[u'A', u'1134', u'1', u'\"BackOffice\"', u'\"/backoffice\"', None]\n",
      "[u'A', u'1135', u'1', u'\"MS Word Support\"', u'\"/mswordsupport\"', None]\n",
      "[u'A', u'1136', u'1', u'\"WorldWide Offices - US Districts\"', u'\"/usa\"', None]\n",
      "[u'A', u'1137', u'1', u'\"About Microsoft \"', u'\"/mscorp\"', None]\n",
      "[u'A', u'1138', u'1', u'\"Developer Magazine\"', u'\"/mind\"', None]\n",
      "[u'A', u'1139', u'1', u'\"MS in K-12 Education\"', u'\"/k-12\"', None]\n",
      "[u'A', u'1140', u'1', u'\"Netherlands (Holland)\"', u'\"/netherlands\"', None]\n",
      "[u'A', u'1141', u'1', u'\"Europe\"', u'\"/europe\"', None]\n",
      "[u'A', u'1142', u'1', u'\"South Africa\"', u'\"/southafrica\"', None]\n",
      "[u'A', u'1143', u'1', u'\"Site Builder Workshop\"', u'\"/workshoop\"', None]\n",
      "[u'A', u'1144', u'1', u'\"For Developers Only News\"', u'\"/devnews\"', None]\n",
      "[u'A', u'1145', u'1', u'\"Visual Fox Pro Support\"', u'\"/vfoxprosupport\"', None]\n",
      "[u'A', u'1146', u'1', u'\"Microsoft Solution Providers\"', u'\"/msp\"', None]\n",
      "[u'A', u'1147', u'1', u'\"Microsoft Financial Forum\"', u'\"/msft\"', None]\n",
      "[u'A', u'1148', u'1', u'\"Channel Resources\"', u'\"/channel_resources\"', None]\n",
      "[u'A', u'1149', u'1', u'\"Advanced Data Connector\"', u'\"/adc\"', None]\n",
      "[u'A', u'1150', u'1', u'\"Internet Information Server News\"', u'\"/infoserv\"', None]\n",
      "[u'A', u'1151', u'1', u'\"MS PowerPoint Support\"', u'\"/mspowerpointsupport\"', None]\n",
      "[u'A', u'1152', u'1', u'\"Russia\"', u'\"/rus\"', None]\n",
      "[u'A', u'1153', u'1', u'\"Venezuela\"', u'\"/venezuela\"', None]\n",
      "[u'A', u'1154', u'1', u'\"MS Project\"', u'\"/project\"', None]\n",
      "[u'A', u'1155', u'1', u'\"Sidewalk\"', u'\"/sidewalk\"', None]\n",
      "[u'A', u'1156', u'1', u'\"Powered by BackOffice\"', u'\"/powered\"', None]\n",
      "[u'A', u'1157', u'1', u'\"Windows 32 bit developer\"', u'\"/win32dev\"', None]\n",
      "[u'A', u'1158', u'1', u'\"Interactive Media Technologies\"', u'\"/imedia\"', None]\n",
      "[u'A', u'1159', u'1', u'\"Transaction Server\"', u'\"/transaction\"', None]\n",
      "[u'A', u'1160', u'1', u'\"Visual C Support\"', u'\"/visualcsupport\"', None]\n",
      "[u'A', u'1161', u'1', u'\"Works Support\"', u'\"/workssupport\"', None]\n",
      "[u'A', u'1162', u'1', u'\"IIS Support\"', u'\"/infoservsupport\"', None]\n",
      "[u'A', u'1163', u'1', u'\"Open Type\"', u'\"/opentype\"', None]\n",
      "[u'A', u'1164', u'1', u'\"Systems Management Server\"', u'\"/smsmgmt\"', None]\n",
      "[u'A', u'1165', u'1', u'\"Poland\"', u'\"/poland\"', None]\n",
      "[u'A', u'1166', u'1', u'\"Mexico\"', u'\"/mexico\"', None]\n",
      "[u'A', u'1167', u'1', u'\"Windows Hardware Testing\"', u'\"/hwtest\"', None]\n",
      "[u'A', u'1168', u'1', u'\"Sales Information (infobase)\"', u'\"/salesinfo\"', None]\n",
      "[u'A', u'1169', u'1', u'\"MS Project\"', u'\"/msproject\"', None]\n",
      "[u'A', u'1170', u'1', u'\"Microsoft Mail\"', u'\"/mail\"', None]\n",
      "[u'A', u'1171', u'1', u'\"MS Merchant\"', u'\"/merchant\"', None]\n",
      "[u'A', u'1172', u'1', u'\"Belgium\"', u'\"/belgium\"', None]\n",
      "[u'A', u'1173', u'1', u'\"Microsoft OnLine Institute\"', u'\"/moli\"', None]\n",
      "[u'A', u'1174', u'1', u'\"New Zealand\"', u'\"/nz\"', None]\n",
      "[u'A', u'1175', u'1', u'\"MS Project Support\"', u'\"/msprojectsupport\"', None]\n",
      "[u'A', u'1176', u'1', u'\"Java Script Development\"', u'\"/jscript\"', None]\n",
      "[u'A', u'1177', u'1', u'\"Master Marketing Calendar\"', u'\"/events\"', None]\n",
      "[u'A', u'1178', u'1', u'\"msdownload.\"', u'\"/msdownload.\"', None]\n",
      "[u'A', u'1179', u'1', u'\"Colombia\"', u'\"/colombia\"', None]\n",
      "[u'A', u'1180', u'1', u'\"Slovenija\"', u'\"/slovenija\"', None]\n",
      "[u'A', u'1181', u'1', u'\"Kids Support\"', u'\"/kidssupport\"', None]\n",
      "[u'A', u'1182', u'1', u'\"Fortran\"', u'\"/fortran\"', None]\n",
      "[u'A', u'1183', u'1', u'\"Italy\"', u'\"/italy\"', None]\n",
      "[u'A', u'1184', u'1', u'\"MS Excel Support\"', u'\"/msexcelsupport\"', None]\n",
      "[u'A', u'1185', u'1', u'\"SNA Server\"', u'\"/sna\"', None]\n",
      "[u'A', u'1186', u'1', u'\"Job Listings for Pre-Grads\"', u'\"/college\"', None]\n",
      "[u'A', u'1187', u'1', u'\"ODBC Development\"', u'\"/odbc\"', None]\n",
      "[u'A', u'1188', u'1', u'\"Korea\"', u'\"/korea\"', None]\n",
      "[u'A', u'1189', u'1', u'\"Internet News\"', u'\"/internet\"', None]\n",
      "[u'A', u'1190', u'1', u'\"Repository\"', u'\"/repository\"', None]\n",
      "[u'A', u'1191', u'1', u'\"Management\"', u'\"/management\"', None]\n",
      "[u'A', u'1192', u'1', u'\"Visual J++ Support\"', u'\"/visualjsupport\"', None]\n",
      "[u'A', u'1193', u'1', u'\"Office Developer Support\"', u'\"/offdevsupport\"', None]\n",
      "[u'A', u'1194', u'1', u'\"China\"', u'\"/china\"', None]\n",
      "[u'A', u'1195', u'1', u'\"Portugal\"', u'\"/portugal\"', None]\n",
      "[u'A', u'1196', u'1', u'\"ie40\"', u'\"/ie40\"', None]\n",
      "[u'A', u'1197', u'1', u'\"SQL Support\"', u'\"/sqlsupport\"', None]\n",
      "[u'A', u'1198', u'1', u'\"Picture It\"', u'\"/pictureit\"', None]\n",
      "[u'A', u'1199', u'1', u'\"feedback\"', u'\"/feedback\"', None]\n",
      "[u'A', u'1200', u'1', u'\"Benelux Region\"', u'\"/benelux\"', None]\n",
      "[u'A', u'1201', u'1', u'\"MS Hardware\"', u'\"/hardware\"', None]\n",
      "[u'A', u'1202', u'1', u'\"Advanced Technology\"', u'\"/advtech\"', None]\n",
      "[u'A', u'1203', u'1', u'\"Denmark\"', u'\"/danmark\"', None]\n",
      "[u'A', u'1204', u'1', u'\"MS Schedule+\"', u'\"/msscheduleplus\"', None]\n",
      "[u'A', u'1205', u'1', u'\"Hardware Supprt\"', u'\"/hardwaresupport\"', None]\n",
      "[u'A', u'1206', u'1', u'\"Volume Purchasing Options\"', u'\"/select\"', None]\n",
      "[u'A', u'1207', u'1', u'\"Internet Control Pack \"', u'\"/icp\"', None]\n",
      "[u'A', u'1208', u'1', u'\"Israel\"', u'\"/israel\"', None]\n",
      "[u'A', u'1209', u'1', u'\"Turkey\"', u'\"/turkey\"', None]\n",
      "[u'A', u'1210', u'1', u'\"SNA Support\"', u'\"/snasupport\"', None]\n",
      "[u'A', u'1211', u'1', u'\"SMSMGT Support\"', u'\"/smsmgmtsupport\"', None]\n",
      "[u'A', u'1212', u'1', u'\"World Wide Offices\"', u'\"/worldwide\"', None]\n",
      "[u'A', u'1213', u'1', u'\"Corporate Customers\"', u'\"/corporate_solutions\"', None]\n",
      "[u'A', u'1214', u'1', u'\"MS Financial Services\"', u'\"/finserv\"', None]\n",
      "[u'A', u'1215', u'1', u'\"For Developers Only Info\"', u'\"/developer\"', None]\n",
      "[u'A', u'1216', u'1', u'\"Virtual Reality Markup Language\"', u'\"/vrml\"', None]\n",
      "[u'A', u'1217', u'1', u'\"Ireland\"', u'\"/ireland\"', None]\n",
      "[u'A', u'1218', u'1', u'\"MS Publisher Support\"', u'\"/publishersupport\"', None]\n",
      "[u'A', u'1219', u'1', u'\"Corporate Advertising Content\"', u'\"/ads\"', None]\n",
      "[u'A', u'1220', u'1', u'\"Mac Office Support\"', u'\"/macofficesupport\"', None]\n",
      "[u'A', u'1221', u'1', u'\"Microsoft TV Program Information\"', u'\"/mstv\"', None]\n",
      "[u'A', u'1222', u'1', u'\"MS Office News\"', u'\"/msofc\"', None]\n",
      "[u'A', u'1223', u'1', u'\"Finland\"', u'\"/finland\"', None]\n",
      "[u'A', u'1224', u'1', u'\"Authorized Technical Education Center Program\"', u'\"/atec\"', None]\n",
      "[u'A', u'1225', u'1', u'\"Anti Piracy Information\"', u'\"/piracy\"', None]\n",
      "[u'A', u'1226', u'1', u'\"MS Schedule+ Support\"', u'\"/msschedplussupport\"', None]\n",
      "[u'A', u'1227', u'1', u'\"Argentina\"', u'\"/argentina\"', None]\n",
      "[u'A', u'1228', u'1', u'\"Visual Test\"', u'\"/vtest\"', None]\n",
      "[u'A', u'1229', u'1', u'\"Uruguay\"', u'\"/uruguay\"', None]\n",
      "[u'A', u'1230', u'1', u'\"Mail Support\"', u'\"/mailsupport\"', None]\n",
      "[u'A', u'1231', u'1', u'\"Windows NT Developer Support\"', u'\"/win32devsupport\"', None]\n",
      "[u'A', u'1232', u'1', u'\"SiteBuilder Network Specs & Standards\"', u'\"/standards\"', None]\n",
      "[u'A', u'1233', u'1', u'\"vbscripts\"', u'\"/vbscripts\"', None]\n",
      "[u'A', u'1234', u'1', u'\"Office Free Stuff News\"', u'\"/off97cat\"', None]\n",
      "[u'A', u'1235', u'1', u'\"MS Training Evaluation\"', u'\"/onlineeval\"', None]\n",
      "[u'A', u'1236', u'1', u'\"Developing for Global Markets\"', u'\"/globaldev\"', None]\n",
      "[u'A', u'1237', u'1', u'\"Developer Days\"', u'\"/devdays\"', None]\n",
      "[u'A', u'1238', u'1', u'\"Excel Development\"', u'\"/exceldev\"', None]\n",
      "[u'A', u'1239', u'1', u'\"Microsoft Consulting\"', u'\"/msconsult\"', None]\n",
      "[u'A', u'1240', u'1', u'\"Thailand\"', u'\"/thailand\"', None]\n",
      "[u'A', u'1241', u'1', u'\"India\"', u'\"/india\"', None]\n",
      "[u'A', u'1242', u'1', u'\"MS Garden\"', u'\"/msgarden\"', None]\n",
      "[u'A', u'1243', u'1', u'\"MS Usability Group\"', u'\"/usability\"', None]\n",
      "[u'A', u'1244', u'1', u'\"Developer Newswire\"', u'\"/devwire\"', None]\n",
      "[u'A', u'1245', u'1', u'\"Open Financial Connectivity\"', u'\"/ofc\"', None]\n",
      "[u'A', u'1246', u'1', u'\"Developer Media Games\"', u'\"/gamesdev\"', None]\n",
      "[u'A', u'1247', u'1', u'\"Wine Guide\"', u'\"/wineguide\"', None]\n",
      "[u'A', u'1248', u'1', u'\"Softimage \"', u'\"/softimage\"', None]\n",
      "[u'A', u'1249', u'1', u'\"Fortran Support\"', u'\"/fortransupport\"', None]\n",
      "[u'A', u'1250', u'1', u'\"Middle East\"', u'\"/middleeast\"', None]\n",
      "[u'A', u'1251', u'1', u'\"Reference Support\"', u'\"/referencesupport\"', None]\n",
      "[u'A', u'1252', u'1', u'\"Community Affairs\"', u'\"/giving\"', None]\n",
      "[u'A', u'1253', u'1', u'\"MS Word Development\"', u'\"/worddev\"', None]\n",
      "[u'A', u'1254', u'1', u'\"ie3\"', u'\"/ie3\"', None]\n",
      "[u'A', u'1255', u'1', u'\"Message Queue Server\"', u'\"/msmq\"', None]\n",
      "[u'A', u'1256', u'1', u'\"Solutions in Action\"', u'\"/sia\"', None]\n",
      "[u'A', u'1257', u'1', u'\"Professional Developers Series\"', u'\"/devvideos\"', None]\n",
      "[u'A', u'1258', u'1', u'\"Peru\"', u'\"/peru\"', None]\n",
      "[u'A', u'1259', u'1', u'\"controls\"', u'\"/controls\"', None]\n",
      "[u'A', u'1260', u'1', u'\"Exchange Trial\"', u'\"/trial\"', None]\n",
      "[u'A', u'1261', u'1', u'\"MS\\'s Complete Do It Yourself Guide\"', u'\"/diyguide\"', None]\n",
      "[u'A', u'1262', u'1', u'\"Chile\"', u'\"/chile\"', None]\n",
      "[u'A', u'1263', u'1', u'\"Educational Services & Programs\"', u'\"/services\"', None]\n",
      "[u'A', u'1264', u'1', u'\"MS Partner Web\"', u'\"/se_partners\"', None]\n",
      "[u'A', u'1265', u'1', u'\"Source Safe Support\"', u'\"/ssafesupport\"', None]\n",
      "[u'A', u'1266', u'1', u'\"Licenses and Piracy\"', u'\"/licenses\"', None]\n",
      "[u'A', u'1267', u'1', u'\"Caribbean\"', u'\"/caribbean\"', None]\n",
      "[u'A', u'1268', u'1', u'\"javascript\"', u'\"/javascript\"', None]\n",
      "[u'A', u'1269', u'1', u'\"Customer Guides\"', u'\"/business\"', None]\n",
      "[u'A', u'1270', u'1', u'\"developr\"', u'\"/developr\"', None]\n",
      "[u'A', u'1271', u'1', u'\"mdsn\"', u'\"/mdsn\"', None]\n",
      "[u'A', u'1272', u'1', u'\"softlib\"', u'\"/softlib\"', None]\n",
      "[u'A', u'1273', u'1', u'\"mdn\"', u'\"/mdn\"', None]\n",
      "[u'A', u'1274', u'1', u'\"Professional Developer Conference\"', u'\"/pdc\"', None]\n",
      "[u'A', u'1275', u'1', u'\"security.\"', u'\"/security.\"', None]\n",
      "[u'A', u'1276', u'1', u'\"Visual Test Support\"', u'\"/vtestsupport\"', None]\n",
      "[u'A', u'1277', u'1', u'\"NetShow for PowerPoint\"', u'\"/stream\"', None]\n",
      "[u'A', u'1278', u'1', u'\"MS in Higer Education\"', u'\"/hed\"', None]\n",
      "[u'A', u'1279', u'1', u'\"Multimedia Golf\"', u'\"/msgolf\"', None]\n",
      "[u'A', u'1280', u'1', u'\"MS Interactive Music Control\"', u'\"/music\"', None]\n",
      "[u'A', u'1281', u'1', u'\"IntelliMouse\"', u'\"/intellimouse\"', None]\n",
      "[u'A', u'1282', u'1', u'\"home\"', u'\"/home\"', None]\n",
      "[u'A', u'1283', u'1', u'\"Cinemainia\"', u'\"/cinemania\"', None]\n",
      "[u'A', u'1284', u'1', u'\"partner\"', u'\"/partner\"', None]\n",
      "[u'A', u'1287', u'1', u'\"International AutoRoute\"', u'\"/autoroute\"', None]\n",
      "[u'A', u'1288', u'1', u'\"library\"', u'\"/library\"', None]\n",
      "[u'A', u'1289', u'1', u'\"Master Chef Product Information\"', u'\"/masterchef\"', None]\n",
      "[u'A', u'1290', u'1', u'\"Activate the Internet Conference\"', u'\"/devmovies\"', None]\n",
      "[u'A', u'1291', u'1', u'\"news\"', u'\"/news\"', None]\n",
      "[u'A', u'1292', u'1', u'\"MS North Africa\"', u'\"/northafrica\"', None]\n",
      "[u'A', u'1293', u'1', u'\"Encarta\"', u'\"/encarta\"', None]\n",
      "[u'A', u'1294', u'1', u'\"Bookshelf\"', u'\"/bookshelf\"', None]\n",
      "[u'A', u'1295', u'1', u'\"Training\"', u'\"/train_cert\"', None]\n",
      "[u'A', u'1297', u'1', u'\"Central America\"', u'\"/centroam\"', None]\n",
      "\n",
      "\n",
      "There are 294 records\n"
     ]
    }
   ],
   "source": [
    "from reducersideleftjoin import leftjoin\n",
    "mr_job = leftjoin(args=['anonymous-msweb-preprocessed.data','anonymous-msweb.data'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Right join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducersiderightjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersiderightjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.compat import jobconf_from_env\n",
    " \n",
    "class rightjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        #x = line.strip()\n",
    "        #data = re.split(\",\",line)\n",
    "        x = line.split(\",\")\n",
    "        #x = re.split(\",\",line)\n",
    "        if len(x) >1:\n",
    "            ## if we're dealing with the page visiting history:\n",
    "            if x[0]==\"V\":\n",
    "                yield x[0], (\"lefttable\", x[1:])\n",
    "            ## if we're dealing with the page info:\n",
    "            if x[0] == \"A\":   \n",
    "                yield x[0], (\"righttable\", x[1:])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        pagename = list()\n",
    "        pagevisits = list()\n",
    "        for val in values:\n",
    "            if val[0]== u'righttable':\n",
    "                pagevisits.append(val)\n",
    "            else:\n",
    "                pagename.append(val)\n",
    "        # this is what makes the result of the query different\n",
    "        # based on the table on which we are joining:\n",
    "        for o in pagevisits:\n",
    "            if len(pagevisits)==0:\n",
    "                yield None, [key] + [None, None, None] + o[1:]\n",
    "            for c in pagename:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rightjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 0 records\n"
     ]
    }
   ],
   "source": [
    "from reducersiderightjoin import rightjoin\n",
    "mr_job = rightjoin(args=['anonymous-msweb.data','anonymous-msweb-preprocessed.data'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Inner join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducersideinnerjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducersideinnerjoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.compat import jobconf_from_env\n",
    " \n",
    "class innerjoin(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        #x = line.strip()\n",
    "        #data = re.split(\",\",line)\n",
    "        x = line.split(\",\")\n",
    "        #x = re.split(\",\",line)\n",
    "        if len(x) == 5:\n",
    "            ## if we're dealing with the page visiting history:\n",
    "            if x[0]==\"V\":\n",
    "                yield x[0], (\"lefttable\", x[1], x[2], x[3], x[4])\n",
    "            ## if we're dealing with the page info:\n",
    "            if x[0] == \"A\":\n",
    "                yield x[0], (\"righttable\", x[1], x[2], x[3], x[4])\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        pagename = list()\n",
    "        pagevisits = list()\n",
    "        for val in values:\n",
    "            if val[0]== u'lefttable':\n",
    "                pagevisits.append(val)\n",
    "            else:\n",
    "                pagename.append(val)\n",
    "        # inner join:\n",
    "\n",
    "        for o in pagevisits:\n",
    "            for c in pagename:\n",
    "                yield None, [key] + c[1:] + o[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    innerjoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the code through python driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 0 records\n"
     ]
    }
   ],
   "source": [
    "from reducersideinnerjoin import innerjoin\n",
    "mr_job = innerjoin(args=['anonymous-msweb-preprocessed.data','anonymous-msweb.data'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    count = 0\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print value\n",
    "        count = count + 1\n",
    "print \"\\n\"\n",
    "print \"There are %s records\" %count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5.3 EDA of Google n-grams dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "- Longest 5-gram (number of characters). Note if there are ties pick the ngram sort alphabetical order [HINT: think secondary sort where primary sort key is length of ngram in characters, and the secondary sort is ngram string itself]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/bash\r\n"
     ]
    }
   ],
   "source": [
    "!which bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: aws: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://filtered-5grams/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download all the ngram data files, and save them where they can be processed by the mapper and reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing download.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile download.sh\n",
    "#!/usr/bin/bash\n",
    "url=$(awk -F = '{print $2}' url.txt)\n",
    "for i in $(cat file.txt);\n",
    "do \n",
    "wget \"${url}${i}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-07-16 14:22:06--  https://www.dropbox.com/sh/0cv65h44zylqwe3/AADM7tG85Qvup0Ok6wp0WJlua/filtered-5Grams/googlebooks-eng-all-5gram-20090715-5-filtered.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘googlebooks-eng-all-5gram-20090715-5-filtered.txt.1’\n",
      "\n",
      "    [   <=>                                 ] 166,941      240KB/s   in 0.7s   \n",
      "\n",
      "2016-07-16 14:22:08 (240 KB/s) - ‘googlebooks-eng-all-5gram-20090715-5-filtered.txt.1’ saved [166941]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/sh/0cv65h44zylqwe3/AADM7tG85Qvup0Ok6wp0WJlua/filtered-5Grams/googlebooks-eng-all-5gram-20090715-5-filtered.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBMModel=gbm(DaysInHospital~ ., distribution  =\"gaussian\", \r\n",
      "\t\t\ttrainData[,-c(memberIndex,droppedFeatures)], n.trees = numOfTrees, \r\n",
      "\t\t\tshrinkage  =  GBM_SHRINKAGE,\r\n",
      "\t\t\tinteraction.depth=GBM_DEPTH,n.minobsinnode  =  GBM_MINOBS,verbose  =  TRUE, keep.data=FALSE)A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\r\n",
      "A Biography of General George\t92\t90\t74\r\n",
      "A Case Study in Government\t102\t102\t78\r\n",
      "A Case Study of Female\t447\t447\t327\r\n",
      "A Case Study of Limited\t55\t55\t43\r\n",
      "A Child's Christmas in Wales\t1099\t1061\t866\r\n",
      "A Circumstantial Narrative of the\t62\t62\t50\r\n"
     ]
    }
   ],
   "source": [
    "! head googlebooks-eng-all-5gram-20090715-0-filtered.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-06-25 19:09:28--  https://www.dropbox.com/sh/0cv65h44zylqwe3/AABkuM-jAXNVfTaXw6Prj1P1a/filtered-5Grams?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘filtered-5Grams?dl=0’\n",
      "\n",
      "    [     <=>                               ] 522,354      373KB/s   in 1.4s   \n",
      "\n",
      "2016-06-25 19:09:31 (373 KB/s) - ‘filtered-5Grams?dl=0’ saved [522354]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/sh/0cv65h44zylqwe3/AABkuM-jAXNVfTaXw6Prj1P1a/filtered-5Grams?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import sys\n",
    "for line in sys.stdin:\n",
    "    line=line.strip()\n",
    "    ngram=line.split('\\t')[0] #extract product field from second field\n",
    "    length = len(ngram)\n",
    "\n",
    "    print ngram, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing long5gram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile long5gram.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class long5gram(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.map.output.field.separator':'\\t',    \n",
    "            'mapreduce.partition.keycomparator.options': '-k1,1nr -k2',\n",
    "            'mapreduce.job.reduces': '16'\n",
    "        }\n",
    "        JOBCONF_STEP2 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.map.output.field.separator':'\\t',    \n",
    "            'mapreduce.partition.keycomparator.options': '-k1,1nr -k2',\n",
    "            'mapreduce.job.reduces': '1'\n",
    "        }\n",
    "        return [MRStep(\n",
    "            jobconf = JOBCONF_STEP1,    \n",
    "            mapper_init = self.mapper_init,    \n",
    "            mapper = self.mapper,\n",
    "            mapper_final = self.mapper_final,\n",
    "            reducer_init = self.reducer_init,\n",
    "            reducer = self.reducer,\n",
    "            reducer_final = self.reducer_final\n",
    "        ),MRStep(\n",
    "            jobconf = JOBCONF_STEP2,    \n",
    "            mapper = self.mapper_sort,\n",
    "            reducer = self.reducer_sort\n",
    "        )]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.longest = 0\n",
    "        self.longngram = \"\"\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip()\n",
    "        ngram=line.split('\\t')[0] #extract product field from second field\n",
    "        length = len(ngram)\n",
    "        \n",
    "    def mapper_final(self):\n",
    "        yield self.longest, self.longngram\n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.longest = 0\n",
    "        self.longngram = None\n",
    "        self.longngrams = {}\n",
    "    \n",
    "    def reducer(self, key, value):\n",
    "        for v in value:\n",
    "            if key >= self.longest:\n",
    "                self.longest = key\n",
    "                self.longngrams[v] = key\n",
    "                \n",
    "    def reducer_final(self):\n",
    "        for key in self.longngrams.keys():\n",
    "            yield self.longngrams[key], key\n",
    "    \n",
    "    def mapper_sort(self, key, value):\n",
    "        yield key, value\n",
    "    \n",
    "    def reducer_sort(self, key, value):\n",
    "        for v in value:\n",
    "            yield key, v\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    long5gram.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `HW5_3/long5gram': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/long5gram.root.20160716.215005.058897\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/long5gram.root.20160716.215005.058897/files/...\n",
      "STDERR: put: unexpected URISyntaxException\n",
      "Traceback (most recent call last):\n",
      "  File \"long5gram.py\", line 74, in <module>\n",
      "    long5gram.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\n",
      "    mr_job.execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 160, in execute\n",
      "    self.run_job()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 230, in run_job\n",
      "    runner.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/runner.py\", line 473, in run\n",
      "    self._run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 323, in _run\n",
      "    self._upload_local_files_to_hdfs()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 354, in _upload_local_files_to_hdfs\n",
      "    self._upload_to_hdfs(path, uri)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 358, in _upload_to_hdfs\n",
      "    self.fs._put(path, target)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 317, in _put\n",
      "    self.invoke_hadoop(['fs', '-put', local_path, target])\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 179, in invoke_hadoop\n",
      "    raise CalledProcessError(proc.returncode, args)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/hadoop', 'fs', '-put', '/w261/coursework/Untitled Folder/long5gram.py', 'hdfs:///user/root/tmp/mrjob/long5gram.root.20160716.215005.058897/files/long5gram.py']' returned non-zero exit status 1\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r HW5_3/long5gram\n",
    "!python long5gram.py -r hadoop 'googlebooks-eng-all-5gram-20090715-0-filtered.txt' >longest5gram.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test of the first mapper\n",
    "\n",
    "!chmod +x mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python mapper.py googlebooks-eng-all-5gram-20090715-0-filtered.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetic glomerulopathy by pharmacological amelioration 55\r\n",
      "differential reinforcement of successive approximations 55\r\n",
      "oligonucleotide arrays using semiconductor photoresists 55\r\n",
      "Prevention of experimental autoimmune encephalomyelitis 55\r\n",
      "der Verfassungsgebenden Deutschen Nationalversammlung und 57\r\n",
      "Guidelines for clinical intracardiac electrophysiological 57\r\n",
      "Hydroxytryptamine stimulates inositol phosphate production 58\r\n",
      "Interpersonal Communication Interpersonal communication is 58\r\n",
      "E e E e E 9\r\n",
      "interaction.depth=GBM_DEPTH,n.minobsinnode  =  GBM_MINOBS,verbose  =  TRUE, keep.data=FALSE)A BILL FOR ESTABLISHING RELIGIOUS 125\r\n"
     ]
    }
   ],
   "source": [
    "!cat googlebooks-eng-all-5gram-20090715-0-filtered.txt | ./mapper.py |sort -k6 | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## now, we just need to find what caused the map-reduce job above to crash\n",
    "## maybe it couldn't find the jar file, which is in\n",
    "## HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top 10 most frequent words (please use the count information), i.e., unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostfrequentwords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostfrequentwords.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class mostfrequentwords(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "\n",
    "        JOBCONF_STEP1 = {\n",
    "            'stream.num.map.output.key.field':2,\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.map.output.field.separator':',',    \n",
    "            'mapreduce.partition.keycomparator.options': '-k2,2nr',\n",
    "            'mapreduce.job.reduces': '1'\n",
    "        }\n",
    "        return [self.mr(mapper=self.mapper, \n",
    "                        reducer=self.reducer),\n",
    "                self.mr(jobconf=JOBCONF_STEP1,\n",
    "                        mapper=None,\n",
    "                        reducer=self.reducer_sort)\n",
    "               ]\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip()\n",
    "        ngram=line.split('\\t')\n",
    "        words = ngram[0].split()\n",
    "        for word in words: \n",
    "            yield word.lower(), int(ngram[1])\n",
    "    \n",
    "    def reducer(self, key, count):\n",
    "        yield key, sum(count)\n",
    "    \n",
    "    def reducer_sort(self, key, count):\n",
    "        for c in count:\n",
    "            yield key, c\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mostfrequentwords.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `HW5_3/mostfrequentwords': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostfrequentwords.root.20160716.215742.373948\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/mostfrequentwords.root.20160716.215742.373948/files/...\n",
      "STDERR: put: unexpected URISyntaxException\n",
      "Traceback (most recent call last):\n",
      "  File \"mostfrequentwords.py\", line 43, in <module>\n",
      "    mostfrequentwords.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\n",
      "    mr_job.execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 160, in execute\n",
      "    self.run_job()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 230, in run_job\n",
      "    runner.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/runner.py\", line 473, in run\n",
      "    self._run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 323, in _run\n",
      "    self._upload_local_files_to_hdfs()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 354, in _upload_local_files_to_hdfs\n",
      "    self._upload_to_hdfs(path, uri)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 358, in _upload_to_hdfs\n",
      "    self.fs._put(path, target)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 317, in _put\n",
      "    self.invoke_hadoop(['fs', '-put', local_path, target])\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 179, in invoke_hadoop\n",
      "    raise CalledProcessError(proc.returncode, args)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/hadoop', 'fs', '-put', '/w261/coursework/Untitled Folder/mostfrequentwords.py', 'hdfs:///user/root/tmp/mrjob/mostfrequentwords.root.20160716.215742.373948/files/mostfrequentwords.py']' returned non-zero exit status 1\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r HW5_3/mostfrequentwords\n",
    "!python mostfrequentwords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt >mostfrequentwords.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it seems that the problem is the same as before,\n",
    "# so it is something in the settings that is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## given that we must always have pages_count =< count:\n",
    "## take the output of the reducer and count the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordsdensity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordsdensity.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class wordsdensity(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "\n",
    "        JOBCONF_STEP1 = {\n",
    "            'stream.num.map.output.key.field':2,\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.map.output.field.separator':',',    \n",
    "            'mapreduce.partition.keycomparator.options': '-k2,2nr',\n",
    "            'mapreduce.job.reduces': '1'\n",
    "        }\n",
    "        return [self.mr(mapper=self.mapper, \n",
    "                    reducer=self.reducer),\n",
    "                self.mr(jobconf=JOBCONF_STEP2,\n",
    "                    mapper=None,\n",
    "                    reducer=self.reducer_sort)\n",
    "               ]\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip()\n",
    "        ngram=line.split('\\t')\n",
    "        words = ngram[0].split()\n",
    "        for word in words: \n",
    "            yield word.lower(), (int(ngram[1]), int(ngram[2]))\n",
    "    \n",
    "    def reducer(self, key, counts):\n",
    "        ct = 0\n",
    "        pages_ct = 0\n",
    "        for c, pct in counts:\n",
    "            ct += c\n",
    "            pages_ct += pct\n",
    "        yield key, (ct/float(pct))\n",
    "    \n",
    "    def reducer_sort(self, key, count):\n",
    "        for c in count:\n",
    "            yield key, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `HW5_3/wordsdensity': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r HW5_3/wordsdensity\n",
    "!python wordsdensity.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt >wordsdensity.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing histogram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile histogram.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class histogram(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapred.reduce.tasks': '16'\n",
    "        }\n",
    "        \n",
    "        JOBCONF_STEP2 = {\n",
    "            'stream.num.map.output.key.field':2,\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.map.output.field.separator':',',    \n",
    "            'mapreduce.partition.keycomparator.options': '-k1,1nr',\n",
    "            'mapreduce.job.reduces': '1'\n",
    "        }\n",
    "        return [self.mr(jobconf=JOBCONF_STEP1,\n",
    "                        mapper=self.mapper,\n",
    "                        combiner = self.reducer,\n",
    "                        reducer=self.reducer),\n",
    "                self.mr(jobconf=JOBCONF_STEP2,\n",
    "                        mapper=None,\n",
    "                        reducer=self.reducer_sort)\n",
    "               ]\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip()\n",
    "        ngram=line.split('\\t')\n",
    "        yield len(ngram[0]), int(ngram[1])\n",
    "    \n",
    "    def reducer(self, key, count):\n",
    "        yield key, sum(count)\n",
    "    \n",
    "    def reducer_sort(self, key, count):\n",
    "        for c in count:\n",
    "            yield key, c\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    histogram.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `HW5_3/histogram': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/histogram.root.20160716.222949.179715\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/histogram.root.20160716.222949.179715/files/...\n",
      "STDERR: put: unexpected URISyntaxException\n",
      "Traceback (most recent call last):\n",
      "  File \"histogram.py\", line 44, in <module>\n",
      "    histogram.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\n",
      "    mr_job.execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 160, in execute\n",
      "    self.run_job()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 230, in run_job\n",
      "    runner.run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/runner.py\", line 473, in run\n",
      "    self._run()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 323, in _run\n",
      "    self._upload_local_files_to_hdfs()\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 354, in _upload_local_files_to_hdfs\n",
      "    self._upload_to_hdfs(path, uri)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/hadoop.py\", line 358, in _upload_to_hdfs\n",
      "    self.fs._put(path, target)\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 317, in _put\n",
      "    self.invoke_hadoop(['fs', '-put', local_path, target])\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 179, in invoke_hadoop\n",
      "    raise CalledProcessError(proc.returncode, args)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/hadoop', 'fs', '-put', '/w261/coursework/Untitled Folder/histogram.py', 'hdfs:///user/root/tmp/mrjob/histogram.root.20160716.222949.179715/files/histogram.py']' returned non-zero exit status 1\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r HW5_3/histogram\n",
    "!python histogram.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt >histogram.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## it seems that this really is a configuration problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.4 Synonym detection over 2Gig of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please unit test and system test your code with respect \n",
    "to SYSTEMS TEST DATASET and show the results. \n",
    "Please compute the expected answer by hand and show your hand calculations for the \n",
    "SYSTEMS TEST DATASET. Then show the results you get with you system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start with calculation for this systems test dataset.\n",
    "\n",
    "For the items in the example \"DocA, DocB, DocC\":\n",
    "\n",
    "the initial mini-documents are:\n",
    "\n",
    "DocA {X:20, Y:30, Z:5}\n",
    "DocB {X:100, Y:20}\n",
    "DocC {M:5, N:20, Z:5}\n",
    "\n",
    "So then, their first stripes for inverted indices are\n",
    "\n",
    "X: {(DocA, 3), (DocB, 2)}\n",
    "Y: {(DocA, 3), (DocB, 2)}\n",
    "Z: {(DocA, 3), (DocC, 3)}\n",
    "M: {(DocC, 3)}\n",
    "N: {(DocC, 3)}\n",
    "\n",
    "Then, their Jaccard similarity is\n",
    "\n",
    "$$(DocA, DocB) = \\frac{2}{3+2-2} = \\frac{2}{3} = 0.66\n",
    "\n",
    "(DocB, DocC) = \\frac{0}{2+3-0} = 0\n",
    "\n",
    "(DocA, DocC) = \\frac{1}{2+3-1} = \\frac{1}{4} $$\n",
    "\n",
    "and their Cosine similarity is\n",
    "\n",
    "$$(DocA, DocB) = \\frac{2}{\\sqrt{3} \\sqrt{2}} = \\frac{2}{ \\sqrt{6}\n",
    "\n",
    "(DocB, DocC) = \\frac{0}{\\sqrt{2} \\sqrt{3}} = 0\n",
    "\n",
    "(DocA, DocC) = \\frac{1}{ \\sqrt{3} \\sqrt{3}} = \\frac{1}{3} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the example code shows, this can also be used for detection of synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 9001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==Design notes for (1)==\n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "\n",
    "<*word,count>\n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Step 1: find the 10,000 most frequent words\n",
    "\n",
    "## 1.1: create bigrams from all n-grams\n",
    "## 1.2: drop all stop-like words\n",
    "## 1.3: find 10,000 most frequent words\n",
    "## 1.4: build stripes from them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before everything, we got the complete data for all the n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we create bi-grams from all the n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile mapper1.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import sys\n",
    "count = 0\n",
    "\n",
    "for line in sys.stdin:  \n",
    "    line=line.strip()\n",
    "    words=line.split()\n",
    "    # parameter finding how long is the n-gram\n",
    "    n = len(words) - 3\n",
    "    #for word in words:\n",
    "    if n > 2:\n",
    "        for i in range(n-1):\n",
    "            print words[i], words[i+1], words[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then, we remove the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer1.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line=line.strip()\n",
    "    words=line.split()\n",
    "    if words[0] not in stopwords and words[1] not in stopwords:\n",
    "        print words[0], words[1], words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mapper1.py\n",
    "!chmod a+x reducer1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we select the 10,000 bigrams with the highest count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/w261/coursework/Untitled Folder\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the input data into HDFS and make sure the output directory is clear\n",
    "!bin/hdfs dfs -put /w261/coursework/Untitled Folder/googlebooks-eng-all\n",
    "!bin/hdfs dfs -rm -r /user/kuknina/googlebooks-bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bin/hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-mr1.jar\n",
    "-D mapred.map.tasks=1 \\\n",
    "-D mapred.reduce.tasks=2 \\\n",
    "-file ./mapper1.py    -mapper ./mapper1.py \\\n",
    "-file ./reducer1.py   -reducer ./reducer1.py \\\n",
    "-input /googlebooks-eng-all -output /user/kuknina/googlebooks-bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use this to build the stripes:\n",
    "## http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/qcirdwyelyebonp/Extended%20Cosine%20Similarity%20System%20Test%20Example.ipynb?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we change the ngram structure to fit the Similarity tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "#HW 2.2 - Mapper Function Code\n",
    "import sys\n",
    "doc_no = 0\n",
    "for line in sys.stdin:\n",
    "    output_file = open('normalized_stripes.txt', 'w')\n",
    "    line=line.strip()\n",
    "    words=line.split()\n",
    "    # parameter finding how long is the n-gram\n",
    "    n = len(words) - 3\n",
    "    diction = {}\n",
    "    try:\n",
    "        val = int(words[n+2])\n",
    "        for i in range(n):\n",
    "            diction[words[i]] = val\n",
    "        output_file.write(doc_no, diction)\n",
    "        #print doc_no, diction\n",
    "        doc_no +=1\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    #print diction\n",
    "        #if n > 2:\n",
    "            #for i in range(n-1):\n",
    "                #print words[i], words[i+1], words[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat googlebooks-eng-all-5gram-20090715-0-filtered.txt | ./mapper.py   | head -15 #|sort -k6 | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NormalizeStripes()\n",
    "!cat normalized_stripes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "%%writefile reducer.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import ast\n",
    "import math\n",
    "\n",
    "# Create a method that normalizes the binary stripes.\n",
    "def NormalizeStripes():\n",
    "    # Create an output file to write normalized stripes to.\n",
    "    output_file = open('normalized_stripes.txt', 'w')\n",
    "    # Read each line of binarized stripes file.\n",
    "    for line in open('binary_stripes.txt', 'r'):\n",
    "        line = line.strip()\n",
    "        contents = line.split(\"\\t\")\n",
    "        word = contents[0]\n",
    "        # Read in stripe as a dictionary\n",
    "        stripe = dict(ast.literal_eval(contents[1]))\n",
    "        # Get length of stripe to use for normalization.\n",
    "        stripeLen = len(stripe)\n",
    "        # Iterate through each value in stripes dictionary.\n",
    "        for key in stripe:\n",
    "            # Normalize each value by dividing by sqrt(stripeLength).\n",
    "            stripe[key] = float(1)/math.sqrt(stripeLen)\n",
    "        output_file.write(\"\\t\".join([word, str(stripe)]) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now, when the first stage is done, we do the same process\n",
    "#as we did for the words in the small system test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile stripebuilding.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class stripebuilding(MRJob):\n",
    "    def configure_options(self):\n",
    "        super(stripebuilding, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--offset', type='int', default=9000)\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {        \n",
    "        }\n",
    "        JOBCONF_STEP2 = {        \n",
    "        }\n",
    "        return [self.mr(jobconf=JOBCONF_STEP1,\n",
    "                    mapper_init=self.mapper_init,    \n",
    "                    mapper=self.mapper,\n",
    "                    combiner=self.reducer,\n",
    "                    reducer=self.reducer)\n",
    "            ]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        stopwords = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "        'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "        'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "        'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "        'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "        'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "        'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "        'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'])\n",
    "\n",
    "        w = re.compile(r\"[\\w']+\")\n",
    "        x = 0\n",
    "        \n",
    "        self.topfreq10000 = set()\n",
    "        self.basis1000 = set()\n",
    "        with open(\"part-00000\",\"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                if x < 10000:\n",
    "                    line = line.strip().split(\"\\t\")\n",
    "                    word = re.findall(w,line[0])[0]\n",
    "\n",
    "                    if word not in stopwords:\n",
    "                        self.topfreq10000.add(word)\n",
    "                        if x >= self.options.offset:\n",
    "                            self.basis1000.add(word)\n",
    "                        x += 1\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        \n",
    "        STRIPES = {}\n",
    "        \n",
    "        line = line.strip()\n",
    "        ngram,count,page_count,book_count = line.split(\"\\t\")\n",
    "        \n",
    "        words = map(lambda x: x.lower(), ngram.split())\n",
    "        \n",
    "        for w1 in words:\n",
    "            if w1 in self.mostFreq_10000:\n",
    "                STRIPES.setdefault(w1,{}) \n",
    "                for w2 in words:\n",
    "                    if w2 in self.vocab_basis_1000 and w2 != w1:\n",
    "                        STRIPES[w1].setdefault(w2,0)\n",
    "                        STRIPES[w1][w2] += int(count)\n",
    "                \n",
    "                yield w1, STRIPES[w1]\n",
    "\n",
    "    def reducer(self,key,stripes):  \n",
    "        # make a combined stripe from the list of stripes\n",
    "        aggregate_stripe = {}\n",
    "        for stripe in stripes:\n",
    "            for word in stripe:\n",
    "                aggregate_stripe.setdefault(word, 0)\n",
    "                aggregate_stripe[word] += stripe[word]\n",
    "        yield key, aggregate_stripe\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    stripebuilding.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now, we run this, and output to a file in s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 rm --recursive s3://w261-hw5.4/stripes\n",
    "!python buildStripes.py -r emr s3://filtered-5grams/ \\\n",
    "    --cluster-id=j-10BB56N1HW4SH \\\n",
    "    --output-dir=s3://w261-hw5.4/stripes \\\n",
    "    --file=mostFrequent/part-00000 \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==Design notes for (2)==\n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "- Jaccard\n",
    "- Cosine similarity\n",
    "- Spearman correlation\n",
    "- Euclidean distance\n",
    "- Taxicab (Manhattan) distance\n",
    "- Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "- Pearson correlation\n",
    "- Kendall correlation\n",
    "...\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. \n",
    "\n",
    "Please report the size of the cluster used and the amount of time it takes to run for the index construction task and for the synonym calculation task. How many pairs need to be processed (HINT: use the posting list length to calculate directly)? Report your  Cluster configuration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create the inverted indices and calculate similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile simcomparison.py\n",
    "#!/w261/venv/bin/python\n",
    "\n",
    "import collections\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class simcomparison(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "        }\n",
    "        JOBCONF_STEP2 = {  \n",
    "        }\n",
    "        JOBCONF_STEP3 = { \n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        return [MRStep(jobconf=JOBCONF_STEP1,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer)\n",
    "                ,\n",
    "                MRStep(jobconf=JOBCONF_STEP2,\n",
    "                    mapper=self.sim_mapper,\n",
    "                    reducer=self.sim_reducer)\n",
    "                ,\n",
    "                MRStep(jobconf=JOBCONF_STEP3,\n",
    "                    mapper=None,\n",
    "                    reducer=self.reducer_sort)\n",
    "                ]\n",
    "    \n",
    "        \n",
    "   \n",
    "    def mapper(self,_,line):\n",
    "        line = line.strip()\n",
    "        key, stripe = line.split(\"\\t\")\n",
    "        \n",
    "        key = key.replace('\"','')\n",
    "        stripe = json.loads(stripe)\n",
    "        l = len(stripe)\n",
    "        for w in stripe:\n",
    "            yield w, (key, l) \n",
    "        \n",
    "    def reducer(self,key,value):\n",
    "        #this will output the invereted indices for each word\n",
    "        d = collections.defaultdict(list)\n",
    "        for v in value:\n",
    "            d[key].append(v)\n",
    "        yield key,d[key]\n",
    "\n",
    "    def sim_mapper(self,key,inv_indx):\n",
    "        \n",
    "        X = map(lambda x: x[0]+\".\"+str(x[1]) , inv_indx)      \n",
    "        for subset in itertools.combinations(sorted(set(X)), 2):\n",
    "            yield subset[0]+\".\"+subset[1], 1\n",
    "\n",
    "    def sim_reducer(self,key,value):\n",
    "        w1,l_w1,w2,l_w2 = key.split(\".\")\n",
    "        s = sum(value)\n",
    "        \n",
    "        jaccard = s / ( int(l_w1) + int(l_w2) - s )\n",
    "        cosine = s / ( math.sqrt(int(l_w1))*math.sqrt(int(l_w2)) )               \n",
    "        \n",
    "        avg = (jaccard+cosine+dice)/3\n",
    "        yield avg, (w1+\" - \"+w2,cosine,jaccard)\n",
    "    \n",
    "\n",
    "    def reducer_sort(self,key,value):\n",
    "        for v in value:\n",
    "            yield key,v\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    simcomparison.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mrjob create-cluster --max-hours-idle 1\n",
    "\n",
    "!aws s3 rm --recursive s3://w261-hw5.4/similarities\n",
    "!python simcomparison.py -r emr s3://w261-hw5.4/stripes \\\n",
    "    --cluster-id=j-1BGSPMX02IDX \\\n",
    "    --output-dir=s3://w261-hw5.4/similarities \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5.5 Evaluation of synonyms that you discovered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment you will evaluate the success of you synonym detector (developed in response to HW5.4).\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined\n",
    "by your measure in HW5.4, and use the synonyms function in the accompanying\n",
    "python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with nltk.download().\n",
    "\n",
    "For each (word1,word2) pair, check to see if word1 is in the list, \n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other, \n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of \n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I have to admit that it would be better to first get\n",
    "#the previous part working and then evaluate the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
