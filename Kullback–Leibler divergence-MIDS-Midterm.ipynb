{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Using the MRJob Class below  calculate the  KL divergence of the following two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kltext.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile kltext.txt\n",
    "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases. '\\t'\n",
    "\n",
    "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MRjob class for calculating pairwise similarity using K-L Divergence as the similarity measure\n",
    "\n",
    "Job 1: create inverted index (assume just two objects) <P>\n",
    "Job 2: calculate the similarity of each pair of objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job 1: create inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/w261/venv/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!/w261/venv/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#####################################\n",
    "# Solution 2 - preferred approach\n",
    "#####################################\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True \n",
    "    def steps(self):\n",
    "        # for testing in hadoop local, force multiple reducers.\n",
    "        # On AWS-EMR let the framework decide number of reducers.\n",
    "        JOBCONF_STEP1 = {\n",
    "#             \"mapred.map.tasks\":20,\n",
    "#             \"mapred.reduce.tasks\":10\n",
    "        }\n",
    "        JOBCONF_STEP2 = {  \n",
    "#             \"mapred.map.tasks\":20,\n",
    "#             \"mapred.reduce.tasks\":10\n",
    "        }\n",
    "        JOBCONF_STEP3 = { \n",
    "#             'stream.num.map.output.key.field':2,\n",
    "#             'stream.map.output.field.separator':\",\",\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "#            \"mapred.reduce.tasks\":1\n",
    "        }\n",
    "        return [MRStep(jobconf=JOBCONF_STEP1,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer)\n",
    "                ,\n",
    "                MRStep(jobconf=JOBCONF_STEP2,\n",
    "                    mapper=self.mapper_pair_sim,\n",
    "                    reducer=self.reducer_pair_sim)\n",
    "                ,\n",
    "                MRStep(jobconf=JOBCONF_STEP3,\n",
    "                    mapper=None,\n",
    "                    reducer=self.reducer_sort)\n",
    "                ]\n",
    "    \n",
    "        \n",
    "   \n",
    "    def mapper(self,_,line):\n",
    "        '''\n",
    "        Reference:\n",
    "        \"For each term in the document,emits the term as key, and a tuple \n",
    "        consisting of the doc id and term weight as the value.\n",
    "        The MR runtime automatically handles the grouping of these tuples...\"\n",
    "        (https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf)\n",
    "        '''\n",
    "        #####################################################################\n",
    "        # Stripes as input, ie:\n",
    "        # \"absolutely\" {\"falsehood\": 113, \"pyramid\": 47, \"apartments\": 46}\n",
    "        #####################################################################\n",
    "        \n",
    "        line = line.strip()\n",
    "        key, stripe = line.split(\"\\t\")\n",
    "        \n",
    "        key = key.replace('\"','')\n",
    "        stripe = json.loads(stripe)\n",
    "        l = len(stripe)\n",
    "        for w in stripe:\n",
    "            # Store the length of the document for caluculating similarities\n",
    "            yield w, (key, l)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reducer(self,key,value):\n",
    "        '''\n",
    "        Reference con't:\n",
    "        \"...which the reducer then writes out to disk, thus generating the postings.\"\n",
    "        (https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf)\n",
    "        '''\n",
    "        #####################################################################\n",
    "        # Inverted Index as output, ie:\n",
    "        # \"term\" [[\"doc\",doc_length]]\n",
    "        # \"abyss\"\t[[\"absorbed\", 42], [\"absurdity\", 19]]\n",
    "        #####################################################################\n",
    "        d = collections.defaultdict(list)\n",
    "        for v in value:\n",
    "            d[key].append(v)\n",
    "        yield key,d[key]\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    def mapper_pair_sim(self,key,inv_indx):\n",
    "        \n",
    "        '''\n",
    "        @input: lines from inverted index\n",
    "         \"X\" [[\"DocA\", 3], [\"DocB\", 2], [\"DocC\", 3]]\n",
    "        \n",
    "        @output: pairs of doc and doc_length, count the number of pairs\n",
    "        make complex key and count of 1 as value:\n",
    "         DocA.3.DocB.2, 1\n",
    "         DocA.3.DocC.3, 1\n",
    "         DocB.2.DocC.3, 1\n",
    "        '''\n",
    "        \n",
    "        X = map(lambda x: x[0]+\".\"+str(x[1]) , inv_indx)\n",
    "        \n",
    "        # taking advantage of symetry, output only (a,b), but not (b,a)\n",
    "        for subset in itertools.combinations(sorted(set(X)), 2):\n",
    "            yield subset[0]+\".\"+subset[1], 1\n",
    "\n",
    "\n",
    "\n",
    "    def reducer_pair_sim(self,key,value):\n",
    "        w1,w1_len,w2,w2_len = key.split(\".\")\n",
    "        t = sum(value)\n",
    "        \n",
    "        # http://stanford.edu/~rezab/papers/disco.pdf, pg5 - Table1\n",
    "        jaccard = t / ( int(w1_len) + int(w2_len) - t )\n",
    "        cosine = t / ( math.sqrt(int(w1_len))*math.sqrt(int(w2_len)) ) \n",
    "        overlap = t / ( min( int(w1_len), int(w2_len) ) )\n",
    "        dice = ( 2*t ) / ( int(w1_len) + int(w2_len) )               \n",
    "        \n",
    "        avg = (jaccard+cosine+dice)/3\n",
    "        yield avg, (w1+\" - \"+w2,cosine,jaccard,overlap,dice)\n",
    "    \n",
    "\n",
    "    def reducer_sort(self,key,value):\n",
    "        for v in value:\n",
    "            yield key,v\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing invertedIndexOnly.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndexOnly.py\n",
    "#!/w261/venv/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "###################################\n",
    "# Solution 1, Part A\n",
    "###################################\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRinvertedIndexOnly(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True \n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            \"mapred.map.tasks\":20,\n",
    "            \"mapred.reduce.tasks\":10\n",
    "        }\n",
    "        return [MRStep(jobconf=JOBCONF_STEP1,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer)\n",
    "                ]\n",
    "    \n",
    "        \n",
    "   \n",
    "    def mapper(self,_,line):\n",
    "        '''\n",
    "        Reference:\n",
    "        \"For each term in the document,emits the term as key, and a tuple \n",
    "        consisting of the doc id and term weight as the value.\n",
    "        The MR runtime automatically handles the grouping of these tuples...\"\n",
    "        (https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf)\n",
    "        '''\n",
    "        #####################################################################\n",
    "        # Stripes as input, ie:\n",
    "        # \"absolutely\" {\"falsehood\": 113, \"pyramid\": 47, \"apartments\": 46}\n",
    "        #####################################################################\n",
    "        \n",
    "        line = line.strip()\n",
    "        key, stripe = line.split(\"\\t\")\n",
    "        \n",
    "        key = key.replace('\"','')\n",
    "        stripe = json.loads(stripe)\n",
    "        l = len(stripe)\n",
    "        for w in stripe:\n",
    "            # Store the length of the document to use with JACCARD (|A| + |B|)\n",
    "            yield w, (key, l)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reducer(self,key,value):\n",
    "        '''\n",
    "        Reference con't:\n",
    "        \"...which the reducer then writes out to disk, thus generating the postings.\"\n",
    "        (https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf)\n",
    "        '''\n",
    "        #####################################################################\n",
    "        # Inverted Index as output, ie:\n",
    "        # \"term\" [[\"doc\",doc_length]]\n",
    "        # \"abyss\"\t[[\"absorbed\", 42], [\"absurdity\", 19]]\n",
    "        #####################################################################\n",
    "        d = collections.defaultdict(list)\n",
    "        for v in value:\n",
    "            d[key].append(v)\n",
    "        yield key,d[key]\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndexOnly.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\r\n",
      "Creating temp directory /tmp/similarity.root.20160629.233624.595445\r\n",
      "Running step 1 of 3...\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"similarity.py\", line 141, in <module>\r\n",
      "    MRsimilarity.run()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\r\n",
      "    mr_job.execute()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\r\n",
      "    super(MRJob, self).execute()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 160, in execute\r\n",
      "    self.run_job()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/launch.py\", line 230, in run_job\r\n",
      "    runner.run()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/runner.py\", line 473, in run\r\n",
      "    self._run()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/sim.py\", line 172, in _run\r\n",
      "    self._invoke_step(step_num, 'mapper')\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/sim.py\", line 259, in _invoke_step\r\n",
      "    working_dir, env)\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/inline.py\", line 157, in _run_step\r\n",
      "    child_instance.execute()\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 439, in execute\r\n",
      "    self.run_mapper(self.options.step_num)\r\n",
      "  File \"/w261/venv/lib/python2.7/site-packages/mrjob/job.py\", line 504, in run_mapper\r\n",
      "    for out_key, out_value in mapper(key, value) or ():\r\n",
      "  File \"similarity.py\", line 71, in mapper\r\n",
      "    key, stripe = line.split(\"\\t\")\r\n",
      "ValueError: need more than 1 value to unpack\r\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py kltext.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For systems test 1\n",
    "!python invertedIndexOnly.py kltext.txt\n",
    "# output supressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kldivergence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence.py\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "import numpy as np\n",
    "class kldivergence(MRJob):\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            yield key, [index, count[key]*1.0/len(letter_list)]\n",
    "\n",
    "\n",
    "    def reducer1(self, key, values):\n",
    "        #Fill in your code\n",
    "    \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield None, kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                self.mr(reducer=self.reducer2)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kldivergence import kldivergence\n",
    "mr_job = kldivergence(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
